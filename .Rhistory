text_100 = text_sentiment |>
unique(word)|>
group_by(source, word) |>
summarize(sentiment_count = n()) |>
arrange(-count) |>
slice(1:30) |>
ungroup()
# only take the top 100 words
text_100 = text_sentiment |>
group_by(source, word) |>
summarize(sentiment_count = n()) |>
arrange(-count) |>
slice(1:30) |>
ungroup()
# only take the top 100 words
text_100 = text_sentiment |>
group_by(word) |>
summarize(sentiment_count = n()) |>
arrange(-count) |>
slice(1:30) |>
ungroup()
# only take the top 100 words
text_100 = text_sentiment |>
group_by(word) |>
summarize(sentiment_count = n())
# only take the top 100 words
text_100 = text_sentiment |>
group_by(source,word) |>
summarize(sentiment_count = n())
# only take the top 100 words
text_100 = text_sentiment |>
group_by(source,word) |>
summarize(sentiment_count = n())|>
ungroup()
# only take the top 100 words
text_100 = text_sentiment |>
group_by(source,word) |>
unique() |>
ungroup() |>
arrange(-count) |>
slice(1:30) |>
ungroup()
# only take the top 100 words
text_100 = text_sentiment |>
group_by(source,word) |>
unique() |>
ungroup()
# only take the top 100 words
text_100 = text_sentiment |>
group_by(source,word) |>
unique()
# count words & remove stop words
text_groups = text_words |>
group_by(source, word) |>
summarize(count = n()) |>
ungroup() |>
anti_join(stop_words,by="word")
# bind sentiments & remove stop words
text_sentiment = text_groups |>
inner_join(nrc, by="word")
# only take the top 100 words
text_100 = text_groups |>
group_by(source) |>
slice(1:100) |>
ungroup()
library(textstem)
install.packages("textstem")
library(textstem)
# count words & remove stop words (& lemmatize)
text_groups = text_words |>
group_by(source, word) |>
summarize(count = n()) |>
ungroup() |>
anti_join(stop_words,by="word") |>
lemmatize_words(word)
text_words = bind_rows(text_pilot,text_finale) |> # all transcripts are now in one dataframe
mutate(text = str_remove_all(text,"\\[.+?\\]"),
text = str_squish(str_replace_all(text, "[^a-zA-Z']", " ")),
source = as.factor(source))|>
filter(text != "") |>
unnest_tokens(word,text) # data is now tokenized by word!
# count words & remove stop words (& lemmatize)
text_groups = text_words |>
group_by(source, word) |>
summarize(count = n()) |>
ungroup() |>
anti_join(stop_words,by="word") |>
lemmatize_words(word)
# count words & remove stop words (& lemmatize)
text_groups = text_words |>
group_by(source, word) |>
summarize(count = n()) |>
ungroup()
# count words & remove stop words (& lemmatize)
text_groups = text_words |>
group_by(source, word) |>
summarize(count = n()) |>
ungroup() |>
anti_join(stop_words,by="word")
# count words & remove stop words (& lemmatize)
text_groups = text_words |>
group_by(source, word) |>
summarize(count = n(), .groups="drop") |>
anti_join(stop_words,by="word")
View(text_words)
# count words & remove stop words (& lemmatize)
text_groups = text_words |>
group_by(source, word) |>
summarize(count = n(), .groups="drop") |>
anti_join(stop_words,by="word") |>
lemmatize_words(word)
# count words & remove stop words (& lemmatize)
text_groups = text_words |>
group_by(source, word) |>
summarize(count = n(), .groups="drop") |>
anti_join(stop_words,by="word") |>
lemmatize_words()
# count words & remove stop words (& lemmatize)
text_groups = text_words |>
group_by(source, word) |>
summarize(count = n(), .groups="drop") |>
anti_join(stop_words,by="word") |>
mutate(word = lemmatize_words(word))
View(text_groups)
# bind sentiments & remove stop words
text_sentiment = text_groups |>
inner_join(nrc, by="word")
# only take the top 100 words
text_100 = text_groups |>
group_by(source) |>
slice(1:100) |>
ungroup()
text_100_pilot = text_100 |>
filter(source=="pilot")
text_100_finale = text_100 |>
filter(source=="finale")
View(text_100)
ggplot(data = text_100, aes(label = word)) +
geom_text_wordcloud(aes(color = count, size = count), shape = "diamond") +
scale_size_area(max_size = 6) +
scale_color_gradientn(colors = c("darkgreen","blue","purple")) +
facet_wrap(~source)+
theme_minimal()
ggplot(data = text_100, aes(label = word)) +
geom_text_wordcloud(aes(color = count, size = count), shape = "diamond") +
scale_size_area(max_size = 6) +
scale_color_gradientn(colors = c("darkgreen","blue","purple")) +
facet_wrap(~source)+
theme_minimal()
# only take the top 100 words
text_30 = text_groups |>
group_by(source) |>
slice(1:30) |>
ungroup()
text_30_pilot = text_30 |>
filter(source=="pilot")
text_30_finale = text_30 |>
filter(source=="finale")
ggplot(data = text_100, aes(label = word)) +
geom_text_wordcloud(aes(color = count, size = count), shape = "diamond") +
scale_size_area(max_size = 6) +
scale_color_gradientn(colors = c("darkgreen","blue","purple")) +
facet_wrap(~source)+
theme_minimal()
ggplot(data = text_30, aes(label = word)) +
geom_text_wordcloud(aes(color = count, size = count), shape = "diamond") +
scale_size_area(max_size = 6) +
scale_color_gradientn(colors = c("darkgreen","blue","purple")) +
facet_wrap(~source)+
theme_minimal()
View(text_sentiment)
# create sentiment facet wrap
text_sentiment |>
ggplot(aes(x=sentiment,y=count,fill=source)) |>
geom_col()+
facet_wrap(~sentiment)
# create sentiment facet wrap
text_sentiment |>
ggplot(aes(x=sentiment,y=count,fill=source)) +
geom_col()+
facet_wrap(~sentiment)
# create sentiment facet wrap
text_sentiment |>
ggplot(aes(x=sentiment,y=count,fill=source)) +
geom_bar()+
facet_wrap(~sentiment)
# create sentiment facet wrap
text_sentiment |>
ggplot(aes(x=sentiment,y=count,fill=source)) +
geom_col()+
facet_wrap(~sentiment)
# create sentiment facet wrap
text_sentiment |>
ggplot(aes(x=source,y=count)) +
geom_col()+
facet_wrap(~sentiment)
# create sentiment facet wrap
text_sentiment |>
ggplot(aes(x=source,y=count)) +
geom_col()+
facet_wrap(~sentiment)+
theme_minimal()
# create sentiment facet wrap
text_sentiment |>
ggplot(aes(x=source,y=count,color=source)) +
geom_col()+
facet_wrap(~sentiment)+
theme_minimal()
# create sentiment facet wrap
text_sentiment |>
ggplot(aes(x=source,y=count,color=source)) +
geom_col()+
facet_wrap(~sentiment)+
theme_bw()
View(text_words)
# create sentiment facet wrap
text_sentiment |>
ggplot(aes(x=source,y=count,group=word,color=source)) +
geom_col()+
facet_wrap(~sentiment)+
theme_bw()
# create sentiment facet wrap
text_sentiment |>
ggplot(aes(x=source,y=count,group=word,color=source)) +
geom_col()+
facet_wrap(~sentiment)+
theme_bw()+
labs(x="",y="Frequency",title="Graphs of Sentiment Change from Pilot to Finale")
# create sentiment facet wrap
text_sentiment |>
ggplot(aes(x=source,y=count,group=word,color=source)) +
geom_col()+
facet_wrap(~sentiment)+
theme_bw()+
labs(x="",y="Frequency",title="Graphs of Sentiment Change from Pilot to Finale") |>
ggplotly()
# create sentiment facet wrap
text_sentiment |>
ggplot(aes(x=source,y=count,group=word,color=source)) +
geom_col()+
facet_wrap(~sentiment)+
theme_bw()+
labs(x="",y="Frequency",title="Graphs of Sentiment Change from Pilot to Finale") |>
plotly::ggplotly()
# create sentiment facet wrap
graph_sentiment = text_sentiment |>
ggplot(aes(x=source,y=count,group=word,color=source)) +
geom_col()+
facet_wrap(~sentiment)+
theme_bw()+
labs(x="",y="Frequency",title="Graphs of Sentiment Change from Pilot to Finale")
plotly::ggplotly(graph_sentiment)
# create sentiment facet wrap
graph_sentiment = text_sentiment |>
ggplot(aes(x=source,y=count,group=word,color=source,fill=source)) +
geom_col()+
facet_wrap(~sentiment)+
theme_bw()+
labs(x="",y="Frequency",title="Graphs of Sentiment Change from Pilot to Finale")
graph_sentiment
getwd()
text_sentiment |>
group_by(sentiment) |>
mutate(total = n()) |>
ungroup()
sentiment_source = text_sentiment |>
group_by(sentiment) |>
mutate(total = n()) |>
ungroup()
View(sentiment_source)
sentiment_source = text_sentiment |>
group_by(sentiment) |>
summarize(total = n()) |>
ungroup()
sentiment_source = text_sentiment |>
group_by(sentiment,source) |>
summarize(total = n()) |>
ungroup()
sentiment_source = text_sentiment |>
group_by(sentiment,source) |>
summarize(total = n(), .groups="drop")
sentiment_source = text_sentiment |>
group_by(sentiment,source) |>
summarize(log(sum(source==pilot)/sum(source==finale)), .groups = "drop")
sentiment_source = text_sentiment |>
group_by(sentiment,source) |>
summarize(log(sum(source=="pilot")/sum(source=="finale")), .groups = "drop")
sentiment_source = text_sentiment |>
group_by(sentiment,source) |>
summarize(pilot_count = n(source=="pilot"),
finale_count = n(source=="finale"),
log_diff = log(sum(source=="pilot")/sum(source=="finale")), .groups = "drop")
sentiment_source = text_sentiment |>
group_by(sentiment,source) |>
summarize(pilot_count = n(source=="pilot"),
finale_count = n(source=="finale"))
sentiment_source = text_sentiment |>
group_by(sentiment) |>
summarize(pilot_count = n(source=="pilot"),
finale_count = n(source=="finale"))
sentiment_source = text_sentiment |>
group_by(sentiment) |>
summarize(pilot_count = sum(source=="pilot"),
finale_count = sum(source=="finale"))
sentiment_source = text_sentiment |>
group_by(sentiment) |>
summarize(pilot_count = sum(source=="pilot"),
finale_count = sum(source=="finale"),
log_diff = log(pilot_count / finale_count))
sentiment_source = text_sentiment |>
group_by(sentiment) |>
summarize(pilot_count = sum(source=="pilot"),
finale_count = sum(source=="finale"),
log_diff = log(finale_count / pilot_count))
sentiment_source |>
ggplot(aes(x=log_diff,y=sentiment,fill=source))+
geom_col()+
labs(x="Natural Log Ratio of Sentiment Change (Finale / Pilot)",y="Sentiment")
sentiment_source = text_sentiment |>
group_by(sentiment) |>
summarize(pilot_count = sum(source=="pilot"),
finale_count = sum(source=="finale"),
log_diff = log(finale_count / pilot_count),
pos_neg = ifelse(log_ratio_adjust > 0, 'pos', 'neg'))
sentiment_source = text_sentiment |>
group_by(sentiment) |>
summarize(pilot_count = sum(source=="pilot"),
finale_count = sum(source=="finale"),
log_diff = log(finale_count / pilot_count),
pos_neg = ifelse(log_diff > 0, 'pos', 'neg'))
sentiment_source |>
ggplot(aes(x=log_diff,y=sentiment,fill=pos_neg))+
geom_col()+
labs(x="Natural Log Ratio of Sentiment Change (Finale / Pilot)",y="Sentiment")+
scale_fill_viridis_b()
sentiment_source |>
ggplot(aes(x=log_diff,y=sentiment,fill=pos_neg))+
geom_col()+
labs(x="Natural Log Ratio of Sentiment Change (Finale / Pilot)",y="Sentiment",title="Change in Sentiment from Pilot to Finale")+
scale_fill_viridis_b()
sentiment_source |>
ggplot(aes(x=log_diff,y=sentiment))+
geom_col()+
labs(x="Natural Log Ratio of Sentiment Change (Finale / Pilot)",y="Sentiment",title="Change in Sentiment from Pilot to Finale")+
scale_fill_viridis_b()
sentiment_source |>
arrange(-log_diff)|>
ggplot(aes(x=log_diff,y=sentiment))+
geom_col()+
labs(x="Natural Log Ratio of Sentiment Change (Finale / Pilot)",y="Sentiment",title="Change in Sentiment from Pilot to Finale")+
scale_fill_viridis_b()
sentiment_source |>
arrange(-log_diff)
sentiment_source |>
arrange(-log_diff)|>
ggplot(aes(x=log_diff,y=sentiment))+
geom_col()+
labs(x="Natural Log Ratio of Sentiment Change (Finale / Pilot)",y="Sentiment",title="Change in Sentiment from Pilot to Finale")+
scale_fill_viridis_b()
ggplot(aes(x=log_diff,y=fct_reorder(sentiment,-log_diff))+
""
""
sentiment_source |>
ggplot(aes(x=log_diff,y=fct_reorder(sentiment,-log_diff)))+
geom_col()+
labs(x="Natural Log Ratio of Sentiment Change (Finale / Pilot)",y="Sentiment",title="Change in Sentiment from Pilot to Finale")+
scale_fill_viridis_b()
sentiment_source |>
ggplot(aes(x=log_diff,y=fct_reorder(sentiment,log_diff)))+
geom_col()+
labs(x="Natural Log Ratio of Sentiment Change (Finale / Pilot)",y="Sentiment",title="Change in Sentiment from Pilot to Finale")+
scale_fill_viridis_b()
sentiment_source |>
ggplot(aes(x=log_diff,y=fct_reorder(sentiment,log_diff)))+
geom_col()+
labs(x="Natural Log Ratio of Sentiment Change (Finale / Pilot)",y="Sentiment",title="Change in Sentiment from Pilot to Finale")+
scale_fill_viridis_b()+
theme_minimal()
sentiment_source |>
ggplot(aes(x=log_diff,y=fct_reorder(sentiment,log_diff)))+
geom_col()+
labs(x="Natural Log Ratio of Sentiment Change (Finale / Pilot)",y="Sentiment",title="Change in Sentiment from Pilot to Finale")+
scale_fill_manual(value=c("pos"="slateblue","neg"="darkred"))+
theme_minimal()
sentiment_source |>
ggplot(aes(x=log_diff,y=fct_reorder(sentiment,log_diff)),fill=pos_neg)+
geom_col()+
labs(x="Natural Log Ratio of Sentiment Change (Finale / Pilot)",y="Sentiment",title="Change in Sentiment from Pilot to Finale")+
scale_fill_manual(value=c("pos"="slateblue","neg"="darkred"))+
theme_minimal()
sentiment_source |>
ggplot(aes(x=log_diff,y=fct_reorder(sentiment,log_diff),fill=pos_neg))+
geom_col()+
labs(x="Natural Log Ratio of Sentiment Change (Finale / Pilot)",y="Sentiment",title="Change in Sentiment from Pilot to Finale")+
scale_fill_manual(value=c("pos"="slateblue","neg"="darkred"))+
theme_minimal()
sentiment_source |>
ggplot(aes(x=log_diff,y=fct_reorder(sentiment,log_diff),fill=pos_neg))+
geom_col()+
labs(x="Natural Log Ratio of Sentiment Change (Finale / Pilot)",y="Sentiment",title="Change in Sentiment from Pilot to Finale")+
scale_fill_manual(values=c("pos"="slateblue","neg"="darkred"))+
theme_minimal()
sentiment_source |>
ggplot(aes(x=log_diff,y=fct_reorder(sentiment,log_diff),fill=pos_neg))+
geom_col()+
labs(x="Natural Log Ratio of Sentiment Change (Finale / Pilot)",y="Sentiment",title="Change in Sentiment from Pilot to Finale")+
scale_fill_manual(values=c("pos"="slateblue","neg"="darkred"))+
theme_minimal()+
theme(legend.position = "none")
library(janitor)
library(data.table)
library(here)
#| code-summary: "Code: Import Data"
#| output: FALSE
### Packages
library(tidyverse)
library(tidytext)
library(pdftools)
library(ggwordcloud)
library(textdata)
library(textstem)
library(janitor)
library(data.table)
library(here)
### Data Import
text_pilot = fread(here("data","pilot.txt"), sep="\n") |>
clean_names() |>
rename(text=upbeat_dance_pop_song_plays)|>
mutate(source="pilot")
text_finale = fread(here("data","finale.txt"), sep="\n") |>
clean_names() |>
rename(text=like_to_be_the_center_of_attention) |>
mutate(source="finale")
text_words = bind_rows(text_pilot,text_finale) |> # all transcripts are now in one dataframe
mutate(text = str_remove_all(text,"\\[.+?\\]"),
text = str_squish(str_replace_all(text, "[^a-zA-Z']", " ")),
source = as.factor(source, ordered=TRUE))|>
filter(text != "") |>
unnest_tokens(word,text) # data is now tokenized by word!
text_words = bind_rows(text_pilot,text_finale) |> # all transcripts are now in one dataframe
mutate(text = str_remove_all(text,"\\[.+?\\]"),
text = str_squish(str_replace_all(text, "[^a-zA-Z']", " ")),
source = as.factor(source, levels("pilot","finale")))|>
filter(text != "") |>
unnest_tokens(word,text) # data is now tokenized by word!
factors = c("pilot","finale")
text_words = bind_rows(text_pilot,text_finale) |> # all transcripts are now in one dataframe
mutate(text = str_remove_all(text,"\\[.+?\\]"),
text = str_squish(str_replace_all(text, "[^a-zA-Z']", " ")),
source = as.factor(source, levels(factors),ordered=TRUE))|>
filter(text != "") |>
unnest_tokens(word,text) # data is now tokenized by word!
text_words = bind_rows(text_pilot,text_finale) |> # all transcripts are now in one dataframe
mutate(text = str_remove_all(text,"\\[.+?\\]"),
text = str_squish(str_replace_all(text, "[^a-zA-Z']", " ")),
source = factor(source, levels=factors,ordered=TRUE))|>
filter(text != "") |>
unnest_tokens(word,text) # data is now tokenized by word!
ggplot(data = text_30, aes(label = word)) +
geom_text_wordcloud(aes(color = count, size = count), shape = "diamond") +
scale_size_area(max_size = 6) +
scale_color_gradientn(colors = c("darkgreen","blue","purple")) +
facet_wrap(~source)+
theme_minimal()
#| code-summary: "Code: Create wordclouds"
#| fig-cap: ""
# only take the top 30 words
text_30 = text_groups |>
group_by(source) |>
slice(1:30) |>
ungroup()
text_30_pilot = text_30 |>
filter(source=="pilot")
text_30_finale = text_30 |>
filter(source=="finale")
ggplot(data = text_30, aes(label = word)) +
geom_text_wordcloud(aes(color = count, size = count), shape = "diamond") +
scale_size_area(max_size = 6) +
scale_color_gradientn(colors = c("darkgreen","blue","purple")) +
facet_wrap(~source)+
theme_minimal()
View(text_groups)
unique(text_words$words)
unique(text_words$word)
View(text_groups)
count(unique(text_groups))
sentiment_source |>
ggplot(aes(x=log_diff,y=fct_reorder(sentiment,log_diff),fill=pos_neg))+
geom_col()+
labs(x="Log Ratio of Sentiment Change (Finale / Pilot)",y="Sentiment",title="Change in Sentiment from Pilot to Finale")+
scale_fill_manual(values=c("pos"="slateblue","neg"="darkred"))+
theme_minimal()+
theme(legend.position = "none")
View(text_groups)
View(text_groups)
View(text_groups)
words_removed = text_groups |>
filter(word %in% text_sentiment$word)
View(words_removed)
words_removed = text_groups |>
filter(word %in% text_sentiment$word) |>
unique(word)
words_removed = text_groups |>
filter(word %in% text_sentiment$word) |>
distinct(word)
View(words_removed)
View(text_sentiment)
words_removed = text_groups |>
filter(!(word %in% text_sentiment$word)) |>
distinct(word)
View(words_removed)
View(text_sentiment)
